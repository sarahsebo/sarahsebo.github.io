<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Sarah Sebo</title>

    <!-- favicon -->
    <link rel="shortcut icon" href="http://identity.yale.edu/sites/all/themes/yalenew_base/images/favicon.ico" type="image/vnd.microsoft.icon">

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Boostrap Social -->
    <link href="css/bootstrap-social.css" rel="stylesheet">
    
    <!-- Font Awesome -->
    <link rel="stylesheet" href="css/font-awesome.min.css">  
    <link rel="stylesheet" type="text/css" href="css/font-awesome.css">

    <!-- My CSS -->
    <link href="css/custom.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-153732727-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-153732727-1');
    </script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>

    <nav class="navbar navbar-default navbar-custom">
      <div class="container-fluid centered-body">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="title" href="index.html">Sarah Strohkorb Sebo</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right navbar-nav-custom">
            <li><a href="index.html">Home</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li class="active-custom"><a href="research.html">Research</a></li>
            <li><a href="documents/Strohkorb_Sebo_CV_03_09_2020.pdf" target="_blank">CV</a></li>
        </div><!-- /.navbar-collapse -->
      </div><!-- /.container-fluid -->
    </nav>




    <!-- PAGE SPECIFIC CONTENT --> 

    <div class="centered-body">

      <div class="row">
        <div class="col-md-12">
          I develop robots that improve the performance of human-robot teams by shaping team dynamics to promote inclusion, trust, and cohesion. My work focuses on (1) developing data-driven computational models to link low-level social cues to team dynamics and inform intelligent robot decision making and (2) studying how a robot can shape key team dynamics through human subjects experiments.
          <!-- Human social behavior in groups is richly interconnected and highly nuanced, presenting computational challenges for sensing group-level dynamics from individual behavior. I build robots that not only perceive these dynamics, but also positively influence the behavior of group members through social cues and verbal interaction. Using computational models that detect relevant verbal and nonverbal social cues, predict high-level social dynamics, and generate decision-making policies for robot actions, I explore how a robot’s actions within a group shape human team members’ behavior. -->
        </div>
      </div>

      <div class="row">
        <div class="col-xs-12">
          <h3 class="strong-colored-text">Modeling Social Team Dynamics</h3>
        </div>
      </div>

      <hr/>

      <!-- Backchannels -->

      <div class="row">
        <div class="col-md-12">
          <h4 class="light-text">Using Backchannels to Model Group Dynamics</h4>
        </div>
        <div class="col-md-4 research-project-img">
          <img src="img/projects/bb_backchannels_w_speech_bubbles.png" class="img-responsive" alt="Backchanneling">
        </div>
        <div class="col-md-8">
          Currently, group dynamics such as psychological safety, cohesion, and trust are measured through surveys and questionnaires, and there are currently no real-time systems that can detect group characteristics that have been shown to be critical to group success. I am currently investigating the correlation of backchannels (e.g. "yeah", "mm-hmm", nodding) in high-level group dynamics, and am in the process of building a real-time system that can both capture instances of backchannels and, from those backchannels, predict the current group dynamics. 
        </div>
      </div>

      <!-- AT-POMDP -->

      <div class="row">
        <div class="col-md-12">
          <h4 class="light-text">Taking Affective States Into Account in Robot Decision Making Policies</h4>
        </div>
        <div class="col-md-4 research-project-img">
          <img src="img/projects/atpomdp.png" class="img-responsive" alt="Assistive Tutor POMDP">
        </div>
        <div class="col-md-8">
          For robots that interact with people, it is critical that their decision making policies take into account the social and affective states of the people with whom they are interacting. 
          One example of this is one-on-one robot tutoring. 
          Tutoring robots must be aware of the student's math knowledge (mental state) as well as their engagement with the task (engagement state). <br> <br>
          My colleague, Aditi Ramachandran, and I formulated the problem of selecting the right help for a student, accounting for both their mental and engagement states using a partially observable Markov decision process. We evaluated this approach through a between-subjects field study with 4th grade students receiving one-on-one tutoring from a robot over 5 sessions. This work was published at <b>AAAI 2019</b>.
          &nbsp;
          <a href="documents/Ramachandran_Sebo_AAAI_2018.pdf" target="_blank"><img src="img/pdficon_small.png" class="noborder" alt="Download PDF" title="Download PDF" data-pin-nopin="true"></a>
        </div>
      </div>

      <!-- Social Dominance -->

      <div class="row">
        <div class="col-md-12">
          <h4 class="light-text">Automatically Detecting Social Dominance in Children</h4>
        </div>
        <div class="col-md-4 research-project-img">
          <img src="img/projects/social-dominance.jpg" class="img-responsive" alt="Social Dominance">
        </div>
        <div class="col-md-8">
          As robots become more widely used in educational contexts, there is an increasing need to understand group dynamics and for robots to tailor their interactions to individual differences between children. One important factor in group interactions is social dominance, which is expressed through both verbal and nonverbal behaviors. <br> <br> 
          I explored a method for determining whether a child in a group interaction is 'high' or 'low' in social dominance based on domain-independent verbal and nonverbal behaviors. I implemented several machine learning models to classify the social dominance levels of children interacting with social robots. This work was published at <b>ICMI 2015</b>.
          &nbsp;
          <a href="documents/ICMI-2015.pdf" target="_blank"><img src="img/pdficon_small.png" class="noborder" alt="Download PDF" title="Download PDF" data-pin-nopin="true"></a>
        </div>
      </div>

      <div class="row">
        <div class="col-xs-12">
          <h3 class="strong-colored-text">Shaping Team Dynamics</h3>
        </div>
      </div>

      <hr/>

      <!-- Inclusion -->

      <div class="row">
        <div class="col-md-12">
          <h4 class="light-text">Investigating a Robot's Influence on the Inclusion in Human Members of a Human-Robot Team</h4>
        </div>
        <div class="col-md-4 research-project-img">
          <img src="img/projects/inclusion.png" class="img-responsive" alt="Inclusion">
        </div>
        <div class="col-md-8">
          Inclusion is critical in human teams, and has been shown to be linked to team member commitment as well as team performance. As social robots join human teams, they have the ability to influence the perceived inclusion of their fellow human team members. 
          <br><br>
          I have investigated two strategies to improve the inclusion of the human members of a human-robot team: 1) a specialized role to interact with the robot and 2) supportive utterances from the robot. I discovered that a specialized role to interact with a robot can lead to decreased perceptions of inclusion, however, a robot’s supportive utterances demonstrated an increase of verbal contribution in human team members who were more excluded in a collaborative task. This work will be published at <b>HRI 2020</b>.
          &nbsp;
          <a href="documents/HRI_2020_Sebo_Inclusion.pdf" target="_blank"><img src="img/pdficon_small.png" class="noborder" alt="Download PDF" title="Download PDF" data-pin-nopin="true"></a>
        </div>
      </div>

      <!-- Repairing Trust -->

      <div class="row">
        <div class="col-md-12">
          <h4 class="light-text">Repairing Trust after a Robot Trust Violation</h4>
        </div>
        <div class="col-md-4 research-project-img">
          <img src="img/projects/repairing_trust.JPG" class="img-responsive" alt="Repairing Trust">
        </div>
        <div class="col-md-8">
          Trust is a critical component of human-robot teaming. When robots make errors in their interactions with people (e.g. overheating, failing to recognize speech, running into obstacles), a robot's successful repair of trust will be essential to future interaction. <br><br>
          I investigated the efficacy of both the trust violation framing (competence or integrity) and the trust repair strategy (denial or apology) in a robot's trust repair attempt with a person in a 2x2 between subjects study. Please consult  <a href="documents/HRI_2019_Sebo_I_dont_believe_you.pdf" target="_blank">the paper</a> to examine our results. This work was published at <b>HRI 2019</b>.
          &nbsp;
          <a href="documents/HRI_2019_Sebo_I_dont_believe_you.pdf" target="_blank"><img src="img/pdficon_small.png" class="noborder" alt="Download PDF" title="Download PDF" data-pin-nopin="true"></a>
        </div>
      </div>

      <!-- Vulnerability -->

      <div class="row">
        <div class="col-md-12">
          <h4 class="light-text">Influencing Trust-Related Human Behavior through a Robot's Vulnerable Expressions</h4>
        </div>
        <div class="col-md-4 research-project-img">
          <img src="img/projects/building_trust.jpg" class="img-responsive" alt="Vulnerability">
        </div>
        <div class="col-md-8">
          Trust is also a critical ingredient to positive team dynamics and performance and can be described as the willingness of team members to be vulnerable with one another. I found that human team members in a group with a robot making vulnerable comments, as opposed to neutral comments, were more likely to display vulnerable behavior (e.g. explaining a mistake) to their fellow human team members in the aftermath of a team member’s error in a collaborative game. Through these findings, I was the first to demonstrate that a robot’s behavior can influence how the people in the group interact with one another: the human team members displayed more trusting behavior toward their fellow human team members if the robot they interacted with modeled trust and vulnerability. This work was published at <b>HRI 2018</b>. 
          &nbsp;
          <a href="documents/HRI_2018_Sebo.pdf" target="_blank"><img src="img/pdficon_small.png" class="noborder" alt="Download PDF" title="Download PDF" data-pin-nopin="true"></a>
        </div>
      </div>

      <!-- Perceptions of Performance -->

      <div class="row">
        <div class="col-md-12">
          <h4 class="light-text">Examining the Influence of Robot Relationship and Task Focused Questions on Collaborative Performance</h4>
        </div>
        <div class="col-md-4 research-project-img">
          <img src="img/projects/rocket_collaboration.jpg" class="img-responsive" alt="Robot Questions">
        </div>
        <div class="col-md-8">
          Cohesion and collaboration are skills necessary to teamwork that begin to emerge around the age of 5. To examine possible ways a robot can influence the cohesion between team members as collaborative skills are being developed, I investigated the influence of task-focused and relationship-focused discussion questions administered by a robot companion during a collaborative task completed by two children. Although the question type did not influence ratings on a cohesion questionnaire, I found that relationship-focused questions, as opposed to task-focused questions, led children to have higher perceptions of their team’s performance. This work was published at <b>RO-MAN 2016</b>.
          &nbsp;
          <a href="documents/ROMAN-2016.pdf" target="_blank"><img src="img/pdficon_small.png" class="noborder" alt="Download PDF" title="Download PDF" data-pin-nopin="true"></a>
        </div>
      </div>

      <!-- Repairing Trust project --> 
<!--       <div class="row">
        <div class="col-xs-12">
          <h3 class="light-text">Exploring Ways of Repairing Human-Robot Trust</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-md-3 research-project-img">
          <img src="" class="img-responsive" alt="Repairing Trust">
        </div>
        <div class="col-md-9 research-project-text">
          <p class="dark-text">
            
          </p>
          <p class="dark-text">
            Our results were published at <b>HRI 2018</b>. 
            &nbsp;
            <a href=# target="_blank"><img src="img/pdficon_small.png" class="noborder" alt="Download PDF" title="Download PDF" data-pin-nopin="true"></a>
            &nbsp;
            <a href=# target="_blank"><img src="img/chromeicon_small.png" class="noborder" alt="HTML version" title="HTML version" data-pin-nopin="true"></a>
          </p> 
        </div>
      </div>

      <hr/> -->

      <!-- Building Trust project --> 
<!--       <div class="row">
        <div class="col-xs-12">
          <h3 class="light-text">Robots that Influence Human-Human Trust-Related Behaviors in a Team</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-md-3 research-project-img">
          <img src="img/projects/building_trust_experiment_setup.png" class="img-responsive" alt="Group Trust">
        </div>
        <div class="col-md-9 research-project-text">
          <p class="dark-text">
            As robots become increasingly incorporated in teams with humans, robots must not only be able to perform their tasks accurately, but also contribute positively to the social dynamics of the team. If groups have high levels of group trust or psychological safety (the shared belief that group members are safe to take risks, admit mistakes, and ask for help without fearing social judgment), they are able to more effectively learn from mistakes and grow in productivity as a team. In a study with groups of three adult participants, we explored how a social robot can improve interpersonal trust between members of a group by having a robot make vulnerable statements consistently throughout a collaborative game. We found that during times of tension, human teammates in a group with a robot making vulnerable statements were more likely to explain their failure to the group, console team members who had made mistakes, and laugh together, all actions that reduce the amount of tension experienced by the team. These results suggest that a robot’s vulnerable behavior can have “ripple effects” on their human team members’ expressions of trust-related behavior.
          </p>
          <p class="dark-text">
            Our results were published at <a href="documents/HRI_2018_Sebo.pdf" target="_blank">HRI 2018</a>. 
          </p> 
        </div>
      </div>

      <hr/> -->

      <!-- Rocket Collaboration project --> 
<!--       <div class="row">
        <div class="col-xs-12">
          <h3 class="light-text">Promoting Collaboration between Children with a Social Robot</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-md-3 research-project-img">
          <img src="img/projects/collaboration_setup_w_participants.png" class="img-responsive" alt="Child Collaboration">
        </div>
        <div class="col-md-9 research-project-text">
          <p class="dark-text">
            Despite the growing body of research in human-robot collaboration, there has been little focus on how social robots can support human-to-human teaming. I am interested in investigating whether a social robot can improve human-human collaborative behavior while working on teaming tasks. In a study with six to nine year old children, my colleagues and I investigated whether asking children directed task-focused, relationally-focused questions, or no questions had an effect on their performance in a collaborative task (a touch-screen build-a-rocket game) and their perceptions of their performance. We found that participants who were asked task-focused questions had higher performance scores in the collaborative game than the other groups, however, had a lower perception of their performance than the participants who were asked relationally-focused questions.
          </p>
          <p class="dark-text">
            Our results were be published at <a href="documents/ROMAN-2016.pdf">RO-MAN 2016</a>. 
          </p> 
        </div>
      </div>

      <hr/> -->

      <!-- Social Dominance project --> 
<!--       <div class="row">
        <div class="col-xs-12">
          <h3 class="light-text">The Detection of Social Dominance in Children</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-md-3 research-project-img">
          <img src="img/projects/social-dominance.jpg" class="img-responsive" alt="Social Dominance">
        </div>
        <div class="col-md-9 research-project-text">
          <p class="dark-text">
            As robots become more widely used in educational contexts, there is an increasing need to understand group dynamics and for robots to tailor their interactions to individual differences between children. One important factor in group interactions is social dominance, which is expressed through both verbal and nonverbal behaviors. I explored a method for determining whether a child in a group interaction is 'high' or 'low' in social dominance based on domain-independent verbal and nonverbal behaviors. I implemented several machine learning models to classify the social dominance levels of children interacting with social robots.</p>
          <p class="dark-text">
            Our results were published at <a href="documents/ICMI-2015.pdf">ICMI 2015</a>.
          </p> 
        </div>
      </div> -->

    </div>

    <!-- END PAGE SPECIFIC CONTENT --> 

    <!-- footer -->
    <div class="footer">
      <div class="centered-body">
        <div class="row">
          <div class="footer-email dark-text">
            <a href="mailto:sarah.sebo@yale.edu">sarah.sebo@yale.edu</a>
          </div>
          <div class="footer-address">
            51 Prospect Street, New Haven, CT 06511
          </div>
          <div class="footer-social-media-icons">
            <a class="btn btn-social-icon btn-github" href="https://scholar.google.com/citations?user=6gWYMigAAAAJ" target="_blank">
              <img src="img/icons/google-scholar.png"/>
            </a> 
            <a class="btn btn-social-icon btn-linkedin" href="https://www.linkedin.com/in/sarah-sebo-4b208a77/" target="_blank">
              <!-- <span class="fa fa-linkedin"></span> -->
              <img src="img/icons/linkedin.png"/>
            </a>
<!--             <a class="btn btn-social-icon btn-github" href="https://github.com/sstrohkorb">
              <img src="img/icons/github.png"/>
            </a>
            <a class="btn btn-social-icon btn-facebook" href="https://www.facebook.com/sarahmsebo?fref=ts">
              <img src="img/icons/facebook.png"/>
            </a> -->
          </div>
        </div>
      </div>
    </div>
    

  </body>
</html>